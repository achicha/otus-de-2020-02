{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip -O ./data/sentiment.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd /home/jovyan/work/data && unzip sentiment.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://eee0fd17218b:4040\n",
       "SparkContext available as 'sc' (version = 2.4.5, master = local[*], app id = local-1586786518617)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer, HashingTF, Tokenizer, StopWordsRemover, RegexTokenizer}\n",
       "import org.apache.spark.ml.linalg.Vector\n",
       "import org.apache.spark.sql.Row\n",
       "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer, HashingTF, Tokenizer, StopWordsRemover, RegexTokenizer}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataSchema: org.apache.spark.sql.types.StructType = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath: String = ./data/training.1600000.processed.noemoticon.csv\n",
       "data: org.apache.spark.sql.DataFrame = [label: int, tweet: string]\n",
       "trainData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, tweet: string]\n",
       "testData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, tweet: string]\n",
       "cleanedTrainData: org.apache.spark.sql.DataFrame = [label: int, tweet: string]\n",
       "cleanedTestData: org.apache.spark.sql.DataFrame = [label: int, tweet: string]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// import data \n",
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "val dataPath= \"./data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "val data = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    //.withColumn(\"cleaned_tweet\", regexp_replace(regexp_replace(regexp_replace(regexp_replace($\"tweet\", \"@\\\\w+\", \"\"), \"http\\\\S+\", \"\"), \"#\\\\w+\", \"\"), \"[0-9]\", \"\")) // remove mentioned users, links,  hashtags and numbers\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\", \"trim(tweet) as tweet\")\n",
    "\n",
    "// split into train/test\n",
    "val Array(trainData, testData) = data.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "val cleanedTrainData = trainData\n",
    "    .withColumn(\"cleaned_tweet\", regexp_replace(regexp_replace(regexp_replace(regexp_replace($\"tweet\", \"@\\\\w+\", \"\"), \"http\\\\S+\", \"\"), \"#\\\\w+\", \"\"), \"[0-9]\", \"\")) // remove mentioned users, links,  hashtags and numbers\n",
    "    .selectExpr(\"label\", \"cleaned_tweet as tweet\")\n",
    "\n",
    "val cleanedTestData = testData\n",
    "    .withColumn(\"cleaned_tweet\", regexp_replace(regexp_replace(regexp_replace(regexp_replace($\"tweet\", \"@\\\\w+\", \"\"), \"http\\\\S+\", \"\"), \"#\\\\w+\", \"\"), \"[0-9]\", \"\")) // remove mentioned users, links,  hashtags and numbers\n",
    "    .selectExpr(\"label\", \"cleaned_tweet as tweet\")\n",
    "\n",
    "// check\n",
    "// cleanedTrainData.groupBy($\"label\").count.show\n",
    "// cleanedTrainData(5, false)\n",
    "// cleanedTestData.groupBy($\"label\").count.show\n",
    "// cleanedTestData(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer: org.apache.spark.ml.feature.RegexTokenizer = regexTok_54848d624aaf\n",
       "filteredTokenizer: org.apache.spark.ml.feature.StopWordsRemover = stopWords_b0b33133565f\n",
       "hashingTF: org.apache.spark.ml.feature.HashingTF = hashingTF_ffb0f5fffbc1\n",
       "rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_6969fd6a7d46\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_e1c3d5ad6049\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// A tokenizer that converts the input string to lowercase and then splits it by white spaces.\n",
    "val tokenizer = new RegexTokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "    .setPattern(\"\\\\W+\")\n",
    "    .setMinTokenLength(2) // remove <2 char words\n",
    "\n",
    "// remove stop words\n",
    "val filteredTokenizer = new StopWordsRemover()\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"filtered_words\")\n",
    "\n",
    "// transforms the rows for the input column into a sparse term frequency vector.\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(filteredTokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "// create a RandomForest model.\n",
    "val rf = new RandomForestClassifier()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setNumTrees(10)\n",
    "\n",
    "// create pipeline\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, filteredTokenizer, hashingTF, rf))\n",
    "\n",
    "// check\n",
    "//hashingTF.transform(filteredTokenizer.transform(tokenizer.transform(data))).show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train && Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.PipelineModel = pipeline_e1c3d5ad6049\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Train model.\n",
    "val model = pipeline.fit(cleanedTrainData)\n",
    "model.write.overwrite().save(\"./models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+---------------------------------------+----------------------------------------+----------+\n",
      "|label|tweet                                                                                                                                    |words                                                                                                                                      |filtered_words                                                                                                    |features                                                                                                        |rawPrediction                          |probability                             |prediction|\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+---------------------------------------+----------------------------------------+----------+\n",
      "|0    |!  you don't want to shake my hand?                                                                                                      |[you, don, want, to, shake, my, hand]                                                                                                      |[want, shake, hand]                                                                                               |(1000,[423,712,910],[1.0,1.0,1.0])                                                                              |[5.542261473290815,4.457738526709185]  |[0.5542261473290815,0.44577385267091846]|0.0       |\n",
      "|0    |!!  ...nice seeing you out! too bad we didn't get to chat!                                                                               |[nice, seeing, you, out, too, bad, we, didn, get, to, chat]                                                                                |[nice, seeing, bad, didn, get, chat]                                                                              |(1000,[86,141,370,473,788,959],[1.0,1.0,1.0,1.0,1.0,1.0])                                                       |[4.842184668340601,5.157815331659399]  |[0.4842184668340601,0.5157815331659399] |1.0       |\n",
      "|0    |!!!  I left my teddy bear at Kim &amp; Scott's.                                                                                          |[left, my, teddy, bear, at, kim, amp, scott]                                                                                               |[left, teddy, bear, kim, amp, scott]                                                                              |(1000,[2,32,292,662,816,851],[1.0,1.0,1.0,1.0,1.0,1.0])                                                         |[4.958431089879621,5.041568910120379]  |[0.49584310898796213,0.5041568910120379]|1.0       |\n",
      "|0    |!!! WTF at you!! what kinda question is that to ask anybody!!! smeggy jerkoff                                                            |[wtf, at, you, what, kinda, question, is, that, to, ask, anybody, smeggy, jerkoff]                                                         |[wtf, kinda, question, ask, anybody, smeggy, jerkoff]                                                             |(1000,[114,227,275,516,615,839,947],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                              |[4.958431089879621,5.041568910120379]  |[0.49584310898796213,0.5041568910120379]|1.0       |\n",
      "|0    |!!! d jake you are dead to me!                                                                                                           |[jake, you, are, dead, to, me]                                                                                                             |[jake, dead]                                                                                                      |(1000,[224,395],[1.0,1.0])                                                                                      |[4.958431089879621,5.041568910120379]  |[0.49584310898796213,0.5041568910120379]|1.0       |\n",
      "|0    |!!!!!!!!!! OMG!!!!!!! I lost all of my photage and stuff for the new video that was coming out monday... sorry guys looks like no new vid|[omg, lost, all, of, my, photage, and, stuff, for, the, new, video, that, was, coming, out, monday, sorry, guys, looks, like, no, new, vid]|[omg, lost, photage, stuff, new, video, coming, monday, sorry, guys, looks, like, new, vid]                       |(1000,[25,54,173,216,233,318,330,487,498,520,526,784,825],[2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|[5.220198321630952,4.779801678369047]  |[0.5220198321630952,0.4779801678369047] |0.0       |\n",
      "|0    |!Identica currently has rather severe problems concerning performance, availability, and its gateway to Twitter.   !laconica             |[identica, currently, has, rather, severe, problems, concerning, performance, availability, and, its, gateway, to, twitter, laconica]      |[identica, currently, rather, severe, problems, concerning, performance, availability, gateway, twitter, laconica]|(1000,[137,303,437,504,532,622,759,763,797,870,959],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])              |[5.430305447738762,4.569694552261237]  |[0.5430305447738762,0.4569694552261237] |0.0       |\n",
      "|0    |#  Aw, poor you  Hope it's not oinkflu! ;)                                                                                               |[aw, poor, you, hope, it, not, oinkflu]                                                                                                    |[aw, poor, hope, oinkflu]                                                                                         |(1000,[0,5,103,920],[1.0,1.0,1.0,1.0])                                                                          |[4.958431089879621,5.041568910120379]  |[0.49584310898796213,0.5041568910120379]|1.0       |\n",
      "|0    |#  I'm ok, just  really tired. OH is over tantrum but was sick in night so I didn't get much sleep                                       |[ok, just, really, tired, oh, is, over, tantrum, but, was, sick, in, night, so, didn, get, much, sleep]                                    |[ok, really, tired, oh, tantrum, sick, night, didn, get, much, sleep]                                             |(1000,[76,141,310,484,524,582,629,714,845,959,961],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])               |[5.4468941194920175,4.5531058805079825]|[0.5446894119492017,0.45531058805079827]|0.0       |\n",
      "|0    |# number times I bottomed out just in our driveway = ... a . hour trip to mass.. I'm scared                                              |[number, times, bottomed, out, just, in, our, driveway, hour, trip, to, mass, scared]                                                      |[number, times, bottomed, driveway, hour, trip, mass, scared]                                                     |(1000,[128,200,423,527,583,674,782,939],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                      |[5.3715451806861765,4.6284548193138235]|[0.5371545180686177,0.46284548193138236]|0.0       |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+---------------------------------------+----------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- label: integer (nullable = false)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "+-------------------+\n",
      "|  clean_probability|\n",
      "+-------------------+\n",
      "|0.44577385267091846|\n",
      "| 0.5157815331659399|\n",
      "| 0.5041568910120379|\n",
      "| 0.5041568910120379|\n",
      "| 0.5041568910120379|\n",
      "| 0.4779801678369047|\n",
      "| 0.4569694552261237|\n",
      "| 0.5041568910120379|\n",
      "|0.45531058805079827|\n",
      "|0.46284548193138236|\n",
      "| 0.4933351838811838|\n",
      "| 0.4933351838811838|\n",
      "| 0.4549956809317857|\n",
      "| 0.5041568910120379|\n",
      "| 0.4569694552261237|\n",
      "| 0.5041568910120379|\n",
      "| 0.5073635578038755|\n",
      "|0.46284548193138236|\n",
      "| 0.5041568910120379|\n",
      "| 0.5041568910120379|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sameModel: org.apache.spark.ml.PipelineModel = pipeline_e1c3d5ad6049\n",
       "predictionsDF: org.apache.spark.sql.DataFrame = [label: int, tweet: string ... 6 more fields]\n",
       "getProbability: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Make predictions.\n",
    "val sameModel = PipelineModel.load(\"./models/spark-ml-model\")\n",
    "val predictionsDF = sameModel.transform(cleanedTestData)\n",
    "predictionsDF.show(10, false)\n",
    "predictionsDF.printSchema()\n",
    "\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector) => prediction(1))\n",
    "predictionsDF.select(getProbability($\"probability\").alias(\"clean_probability\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
